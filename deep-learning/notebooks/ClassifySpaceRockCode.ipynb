{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 식별 머신을 위한 데이터를 준비한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리를 불러 온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로팅 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# 숫자 처리 라이브러리\n",
    "import numpy as np\n",
    "# 딥러닝을 위한 파이토치 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# 토치비전 라이브러리\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "# 이미지 처리 라이브러리 (PIL, pillow)\n",
    "from PIL import Image\n",
    "# 주피터 노트북에서 plot이 보이도록 설정\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
    "data_dir = '../data'\n",
    "valid_size=0.2\n",
    "\n",
    "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
    "t_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# convert image size to 224x224 for ResNet50 after crop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 변환 방법을 출력하여 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
    "print(t_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 로딩 함수를 작성한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (연습) trainloader와 testloader를 만들어 본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 155\n",
      "    Root location: ../data\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "155 155\n"
     ]
    }
   ],
   "source": [
    "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
    "# make train_data and test_data using datasets.ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "\n",
    "# 학습 데이터의 형식을 확인한다.\n",
    "print(train_data)\n",
    "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154]\n",
      "[95, 2, 41, 128, 143, 93, 74, 50, 146, 22, 123, 26, 43, 87, 40, 115, 15, 52, 90, 56, 28, 102, 9, 111, 1, 119, 16, 139, 108, 7, 131, 77, 85, 136, 18, 51, 120, 118, 125, 63, 106, 21, 135, 32, 44, 89, 78, 134, 49, 65, 12, 33, 110, 47, 153, 69, 104, 88, 29, 147, 57, 132, 5, 91, 8, 122, 149, 23, 96, 141, 62, 142, 55, 20, 27, 126, 61, 98, 112, 121, 71, 127, 6, 101, 133, 116, 80, 117, 151, 25, 45, 68, 105, 114, 11, 72, 37, 81, 19, 53, 94, 67, 84, 75, 97, 60, 144, 38, 83, 35, 79, 13, 31, 54, 17, 82, 129, 70, 36, 76, 14, 150, 66, 73, 138, 124, 130, 10, 0, 3, 107, 109, 24, 34, 46, 152, 92, 148, 103, 59, 42, 140, 58, 39, 4, 30, 99, 64, 113, 100, 48, 137, 154, 145, 86]\n"
     ]
    }
   ],
   "source": [
    "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "\n",
    "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
    "split = int(np.floor(num_train * valid_size))\n",
    "print(split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 85, 136, 18, 51, 120, 118, 125, 63, 106, 21, 135, 32, 44, 89, 78, 134, 49, 65, 12, 33, 110, 47, 153, 69, 104, 88, 29, 147, 57, 132, 5, 91, 8, 122, 149, 23, 96, 141, 62, 142, 55, 20, 27, 126, 61, 98, 112, 121, 71, 127, 6, 101, 133, 116, 80, 117, 151, 25, 45, 68, 105, 114, 11, 72, 37, 81, 19, 53, 94, 67, 84, 75, 97, 60, 144, 38, 83, 35, 79, 13, 31, 54, 17, 82, 129, 70, 36, 76, 14, 150, 66, 73, 138, 124, 130, 10, 0, 3, 107, 109, 24, 34, 46, 152, 92, 148, 103, 59, 42, 140, 58, 39, 4, 30, 99, 64, 113, 100, 48, 137, 154, 145, 86]\n",
      "[95, 2, 41, 128, 143, 93, 74, 50, 146, 22, 123, 26, 43, 87, 40, 115, 15, 52, 90, 56, 28, 102, 9, 111, 1, 119, 16, 139, 108, 7, 131]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "print(train_idx)\n",
    "print(test_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basalt', 'Highland']\n",
      "['Basalt', 'Highland']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, sampler = train_sampler, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, sampler = test_sampler, batch_size = 16)\n",
    "\n",
    "# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드들을 묶어서 load_split_train_test() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)\n",
    "def load_split_train_test(data_dir, valid_size):\n",
    "    t_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(num_train * valid_size))\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler = train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler = test_sampler, batch_size = 16)\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_split_train_test() 함수를 이용하여 trainloader, testloader를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basalt', 'Highland']\n",
      "['Basalt', 'Highland']\n"
     ]
    }
   ],
   "source": [
    "# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.\n",
    "trainloader, testloader = load_split_train_test(data_dir, valid_size=0.2)\n",
    "\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터 샘플들을 살펴본다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 데이터를 로딩한 후 이미지와 레이블을 반환하는 get_random_images() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의 선택한 이미지를 표시해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 이미지와 레이블을 랜덤하게 가져온다.\n",
    "\n",
    "# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.\n",
    "\n",
    "# 학습 데이터의 class 리스트를 얻는다.\n",
    "\n",
    "# 이미지를 표시하기 위한 설정을 한다.\n",
    "\n",
    "# 주피터 노트북에 이미지를 표시한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 모델을 가져와 FCL(Fully Connected Layer)을 수정한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute device를 정한다(CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute device를 정하고 확인한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습된 ResNet50 모델을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 모델을 pretrained=True로 설정한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 수정 전의 ResNet50 모델을 확인해 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCL을 수정한다.(뉴런 구축, 신경망 연결, FCL의 layer 설정 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 신경망 구축 : 전이학습을 위해 모델의 가중치를 freeze 한다.\n",
    "    \n",
    "# 뉴런들을 연결하여 신경망을 생성한다.\n",
    "\n",
    "# q: explain the above code\n",
    "# a: 2048개의 입력을 받아 512개의 출력을 내고, ReLU 함수를 거쳐 0.2의 확률로 Dropout을 적용한다.\n",
    "# 512개의 입력을 받아 2개의 출력을 내고, LogSoftmax 함수를 거쳐 1차원으로 변환한다.\n",
    "# 1차원으로 변환된 출력을 갖는 신경망을 생성한다.\n",
    "\n",
    "# 손실함수를 Cross entropy loss 함수로 지정한다.\n",
    "\n",
    "# why\n",
    "# optimizer를 Adam으로 지정한다.\n",
    "# what is Adam\n",
    "#\n",
    "\n",
    "# 신경망을 compute device로 보낸다.\n",
    "\n",
    "# 종료 여부를 출력한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) FCL을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 FCL을 학습시키고 테스트 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습/검증을 위한 변수를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭 및 출력 간격을 설정한다.\n",
    "\n",
    "# 손실 변수들을 초기화 한다.\n",
    "\n",
    "# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정한 에폭만큼 모델을 학습시키며 검증/평가 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 회수만큼 학습 후 테스트 및 평가해 본다.\n",
    "\n",
    "    # 에폭을 count 한다.\n",
    "\n",
    "    # trainloader로부터 모든 이미지와 레이블을 로드한다.\n",
    "\n",
    "        # 학습 단계를 count 하고 출력한다.\n",
    "\n",
    "        # 입력 데이터(이미지, 레이블)를 device로 보낸다.\n",
    "\n",
    "        # 기존에 학습된 gradient 값을 초기화 한다.(이전에 학습한 값이 영향을 주지 않도록 함)\n",
    "\n",
    "        # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
    "\n",
    "        # 손실(loss) 값들을 계산한다.\n",
    "\n",
    "        # 손실값을 이용하여 gradient를 update한다.\n",
    "\n",
    "        # gradient를 이용하여 설정된 optimizer로 파라미터를 update한다.\n",
    "\n",
    "        # 손실값을 누적/계산한다.\n",
    "\n",
    "        # 학습 단계 5회마다 모델을 테스트/평가 한다.\n",
    "\n",
    "            # 손실과 정확도 변수를 초기화 한다.\n",
    "\n",
    "            # 모델 평가 모드로 전환한다.\n",
    "\n",
    "            # 모델 평가 시 gradient를 계산하지 않도록 한다.\n",
    "\n",
    "                # testloader로부터 모든 이미지와 레이블을 로드한다.\n",
    "\n",
    "                    # 입력 데이터(이미지, 레이블)를 device로 보낸다.\n",
    " \n",
    "                    # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.\n",
    "\n",
    "                    # 손실(loss) 값들을 계산한다.\n",
    "\n",
    "                    # 손실값을 누적시킨다.\n",
    "\n",
    "                    # 로그 확률로부터 진짜 확률값을 계산한다.\n",
    "\n",
    "                    # 가장 큰 확률값과 class를 얻는다. (topk : k번째로 큰 값)\n",
    "\n",
    "                    # 레이블들을 top_class와 동일한 형태로 바꾼 후 같은 값들을 얻는다.\n",
    "\n",
    "                    # equals를 float 텐서로 바꾼 후 평균 정확도를 누적/계산한다.\n",
    "\n",
    "            # 학습 손실값과 테스트 손실값을 추가한다.\n",
    "\n",
    "            # 학습 손실값, 테스트 손실값, 테스트 정확도를 출력한다.\n",
    "\n",
    "            # running_loss 값을 초기화 한다.\n",
    "\n",
    "            # 모델 학습 모드로 전환한다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 학습 손실값과 테스트 손실값을 그래프로 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "\n",
    "\n",
    "# in this graph, what is x-axis? y-axis?\n",
    "# x-axis: epoch\n",
    "# y-axis: loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습/테스트 완료된 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 로드하여 사용할 수 있도록 학습/테스트 완료된 모델을 저장한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 완성된 모델을 사용하여 예측한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장한 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 모델을 불러온다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (확인) 불러온 모델을 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 예측을 위해 predict_image() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5개의 이미지를 임의로 가져와 예측해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 모드로 전환한다.\n",
    "\n",
    "# 5개의 이미지를 랜덤하게 가져온 후 PIL 형식 변환, 표시할 이미지 크기를 설정한다.\n",
    "\n",
    "# 데이터의 class 목록을 얻는다.\n",
    "\n",
    "\n",
    "# 5개의 이미지에 대해 loop를 수행한다.\n",
    "\n",
    "    # 각 이미지에 대해 class를 예측한다.\n",
    "\n",
    "\n",
    "    # 이미지 아래에 class를 표시하도록 설정한다.\n",
    "\n",
    "# 레이블이 추가된 이미지를 보여준다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
