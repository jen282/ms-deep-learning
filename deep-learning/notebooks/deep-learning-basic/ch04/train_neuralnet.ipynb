{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNIST 숫자 데이터를 인식하고 검증하는 코드를 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720081926684
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "sys.path.insert(0, r'C:\\Users\\USER\\ms-deep-learning\\deep-learning\\notebooks\\deep-learning-basic')\n",
        "from dataset.mnist import load_mnist\n",
        "from two_layer_net import TwoLayerNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 읽기\n",
        "(X_train, t_train), (X_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "# 모델 지정\n",
        "network = TwoLayerNet(input_size=784, hidden_size=125, output_size=10)\n",
        "# 하이퍼파라미터 지정\n",
        "iters_num = 10000\n",
        "train_size = X_train.shape[0]\n",
        "batch_size = 300\n",
        "learning_rate = 0.65\n",
        "\n",
        "# 평가를 위한 정확도 리스트\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per__epoch = max(train_size/batch_size, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.14198333333333332 0.1478\n",
            "0.9351666666666667 0.9383\n",
            "0.9568666666666666 0.9546\n",
            "0.9679666666666666 0.9645\n",
            "0.96925 0.9639\n",
            "0.9775 0.9718\n",
            "0.9796 0.9735\n",
            "0.9835166666666667 0.9756\n",
            "0.9847166666666667 0.9754\n",
            "0.9852666666666666 0.9769\n",
            "0.9877333333333334 0.9754\n",
            "0.9898833333333333 0.9779\n",
            "0.9912 0.9786\n",
            "0.9923 0.9797\n",
            "0.9925166666666667 0.9791\n",
            "0.9937333333333334 0.979\n",
            "0.9941833333333333 0.9788\n",
            "0.9948166666666667 0.9801\n",
            "0.9955333333333334 0.98\n",
            "0.9961833333333333 0.979\n",
            "0.9967666666666667 0.9799\n",
            "0.9974166666666666 0.9806\n",
            "0.99705 0.9801\n",
            "0.9979 0.9808\n",
            "0.9978166666666667 0.9807\n",
            "0.9983333333333333 0.9811\n",
            "0.99875 0.9811\n",
            "0.9986333333333334 0.9799\n",
            "0.9991 0.9808\n",
            "0.9986166666666667 0.9815\n",
            "0.99915 0.981\n",
            "0.9987166666666667 0.9799\n",
            "0.9995333333333334 0.9812\n",
            "0.9995 0.9805\n",
            "0.99965 0.9805\n",
            "0.9997833333333334 0.9813\n",
            "0.9997833333333334 0.9808\n",
            "0.99975 0.9814\n",
            "0.9997333333333334 0.9808\n",
            "0.9998166666666667 0.9811\n",
            "0.9997833333333334 0.9807\n",
            "0.9997833333333334 0.9812\n",
            "0.9998333333333334 0.9815\n",
            "0.99985 0.9811\n",
            "0.9998666666666667 0.981\n",
            "0.9998333333333334 0.9811\n",
            "0.9999333333333333 0.9816\n",
            "0.9999333333333333 0.9814\n",
            "0.99995 0.9812\n",
            "0.99995 0.9811\n"
          ]
        }
      ],
      "source": [
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = X_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    # 기울기 계산\n",
        "    # grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % iter_per__epoch == 0:\n",
        "        train_acc = network.accuracy(X_train, t_train)\n",
        "        test_acc = network.accuracy(X_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
